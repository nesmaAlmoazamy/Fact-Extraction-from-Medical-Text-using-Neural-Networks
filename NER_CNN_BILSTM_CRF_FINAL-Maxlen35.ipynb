{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = pd.read_csv(\"ObjectSubset150SentenceLength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ID</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46809</td>\n",
       "      <td>RR</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46809</td>\n",
       "      <td>130/80</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46809</td>\n",
       "      <td>mmHg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47482</td>\n",
       "      <td>RR142/89mmHg,</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47482</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_ID           word     tag\n",
       "0    46809             RR  object\n",
       "1    46809         130/80  object\n",
       "2    46809          mmHg.     NaN\n",
       "3    47482  RR142/89mmHg,  object\n",
       "4    47482             HR     NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS['tag'].fillna('text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ID</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46809</td>\n",
       "      <td>RR</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46809</td>\n",
       "      <td>130/80</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46809</td>\n",
       "      <td>mmHg.</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47482</td>\n",
       "      <td>RR142/89mmHg,</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47482</td>\n",
       "      <td>HR</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47482</td>\n",
       "      <td>76</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47482</td>\n",
       "      <td>x</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47482</td>\n",
       "      <td>min,</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47482</td>\n",
       "      <td>p167cm,</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47482</td>\n",
       "      <td>k89kg.</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47482</td>\n",
       "      <td>EKG-s</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47482</td>\n",
       "      <td>siinusrütmi</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47482</td>\n",
       "      <td>foonil</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47482</td>\n",
       "      <td>ventrikualarsed</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>47482</td>\n",
       "      <td>ekstrasüstolid.</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53393</td>\n",
       "      <td>RR143/87mmHg,</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53393</td>\n",
       "      <td>HR60</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53393</td>\n",
       "      <td>x</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53393</td>\n",
       "      <td>min,</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53393</td>\n",
       "      <td>p180cm,</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_ID             word     tag\n",
       "0     46809               RR  object\n",
       "1     46809           130/80  object\n",
       "2     46809            mmHg.    text\n",
       "3     47482    RR142/89mmHg,  object\n",
       "4     47482               HR    text\n",
       "5     47482               76    text\n",
       "6     47482                x    text\n",
       "7     47482             min,    text\n",
       "8     47482          p167cm,    text\n",
       "9     47482           k89kg.    text\n",
       "10    47482            EKG-s    text\n",
       "11    47482      siinusrütmi    text\n",
       "12    47482           foonil    text\n",
       "13    47482  ventrikualarsed    text\n",
       "14    47482  ekstrasüstolid.    text\n",
       "15    53393    RR143/87mmHg,  object\n",
       "16    53393             HR60    text\n",
       "17    53393                x    text\n",
       "18    53393             min,    text\n",
       "19    53393          p180cm,    text"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"text_ID\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(DS)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pt.', 'text'),\n",
       " ('tehtud', 'text'),\n",
       " ('3', 'text'),\n",
       " ('plasmaferees,', 'text'),\n",
       " ('talus', 'text'),\n",
       " ('hästi.', 'text'),\n",
       " ('Eemaldatud', 'text'),\n",
       " ('700', 'text'),\n",
       " ('ml', 'text'),\n",
       " ('plasmat.', 'text'),\n",
       " ('RR', 'object'),\n",
       " ('112/60', 'object'),\n",
       " ('mmHg.', 'text'),\n",
       " ('Tgasi', 'text'),\n",
       " ('22.10.09.', 'text')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13643"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('sentences5000.txt', 'wb') as f:\n",
    "#   pickle.dump(sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('sentences2000.txt', 'rb') as f:\n",
    "#     sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LengthsList = []\n",
    "for i in range(len(sentences)):\n",
    "    LengthsList.append(len(sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(LengthsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nan\n",
    "\n",
    "words = list(set(DS[\"word\"].values))\n",
    "n_words = len(words)\n",
    "\n",
    "tags = list(set(DS[\"tag\"].values))\n",
    "n_tags = len(tags); \n",
    "\n",
    "\n",
    "from future.utils import iteritems\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "# tag2idx[\"PAD\"] = 0\n",
    "tags2 = [\"PAD\",\"text\",\"object\"]\n",
    "tag2idx = {t: i for i, t in enumerate(tags2)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'PAD', 1: 'text', 2: 'object'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27741"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(s) for s in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# maxlen = max([len(s) for s in sentences])\n",
    "maxlen = 35\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=tag2idx[\"PAD\"], truncating='post')\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"], truncating='post')\n",
    "y = [to_categorical(i, num_classes=n_tags +1) for i in y]\n",
    "\n",
    "# Split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0, 'text': 1, 'object': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import TimeDistributed,SpatialDropout1D,LSTM,MaxPooling1D,Flatten,Embedding, Dense, TimeDistributed, Conv1D,Dropout, Bidirectional\n",
    "import keras as k\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "input = Input(shape=(maxlen,))\n",
    "# Embedding Layer\n",
    "model = Embedding(input_dim=n_words + 2  , output_dim=20, input_length=maxlen)(input)\n",
    "\n",
    "\n",
    "# (number of sentences,  words, 100 output dimension or filters)   \n",
    "# 495,19352,150\n",
    "# batchSize = number of sentences    \n",
    "# length = number of words in each sentence   \n",
    "# channels = dimension of the embedding's output.  \n",
    "# (19352,495)\n",
    "model = Conv1D(filters=20,\n",
    "              kernel_size= 5,  # 3 means 3 words\n",
    "              padding='same',  # valid means no padding\n",
    "              strides=1,  # see explnation above\n",
    "              activation='relu')(model)\n",
    "\n",
    "# model = MaxPooling1D(pool_size=2,padding=\"same\")(model) # (?, 27, 10), (?, 24, 10)\n",
    "# model = Flatten()(model) # (?, 270), (?, 240)\n",
    "\n",
    "# model = LSTM(units=20, \n",
    "#              return_sequences=True, \n",
    "#              recurrent_dropout=0.5)(model)     \n",
    "\n",
    "model = SpatialDropout1D(0.3)(model)\n",
    "\n",
    "# BI-LSTM Layer\n",
    "model = Bidirectional(LSTM(units=20, \n",
    "                           return_sequences=True, \n",
    "                           recurrent_dropout=0.5))(model)\n",
    "\n",
    "\n",
    "\n",
    "# TimeDistributed Layer\n",
    "model = TimeDistributed(Dense(n_tags+1, activation=\"softmax\"))(model)  \n",
    "\n",
    "# CRF Layer\n",
    "crf = CRF(n_tags + 1)\n",
    "\n",
    "out = crf(model)  # output\n",
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)                         (None, 35)                              0              \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)                      (None, 35, 20)                          554860         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                            (None, 35, 20)                          2020           \n",
      "____________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDropout1D)       (None, 35, 20)                          0              \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)              (None, 35, 40)                          6560           \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistributed)         (None, 35, 3)                           123            \n",
      "____________________________________________________________________________________________________\n",
      "crf_1 (CRF)                                  (None, 35, 3)                           27             \n",
      "====================================================================================================\n",
      "Total params: 563,590\n",
      "Trainable params: 563,590\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
    "\n",
    "model.summary(line_length=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GraphViz in c:\\users\\kasutaja\\anaconda3\\envs\\myenv\\lib\\site-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install GraphViz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='CNNmodel.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, to_file='CNNmodel_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9822 samples, validate on 1092 samples\n",
      "Epoch 1/10\n",
      "9822/9822 [==============================] - 12s 1ms/step - loss: 0.5879 - crf_viterbi_accuracy: 0.6922 - accuracy: 0.6841 - val_loss: 0.3653 - val_crf_viterbi_accuracy: 0.7384 - val_accuracy: 0.7353\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73535, saving model to ner-CNN-bi-lstm-model-OBJECT-0.7435.hdf5\n",
      "Epoch 2/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.2490 - crf_viterbi_accuracy: 0.9141 - accuracy: 0.6841 - val_loss: 0.1593 - val_crf_viterbi_accuracy: 0.9877 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73535 to 0.98807, saving model to ner-CNN-bi-lstm-model-OBJECT-0.9935.hdf5\n",
      "Epoch 3/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.1273 - crf_viterbi_accuracy: 0.9863 - accuracy: 0.6841 - val_loss: 0.1039 - val_crf_viterbi_accuracy: 0.9868 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.98807\n",
      "Epoch 4/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.0874 - crf_viterbi_accuracy: 0.9904 - accuracy: 0.6841 - val_loss: 0.0790 - val_crf_viterbi_accuracy: 0.9932 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98807 to 0.99299, saving model to ner-CNN-bi-lstm-model-OBJECT-0.9935.hdf5\n",
      "Epoch 5/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.0648 - crf_viterbi_accuracy: 0.9959 - accuracy: 0.6841 - val_loss: 0.0632 - val_crf_viterbi_accuracy: 0.9950 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.99299 to 0.99485, saving model to ner-CNN-bi-lstm-model-OBJECT-0.9935.hdf5\n",
      "Epoch 6/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.0491 - crf_viterbi_accuracy: 0.9985 - accuracy: 0.6841 - val_loss: 0.0506 - val_crf_viterbi_accuracy: 0.9953 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.99485 to 0.99513, saving model to ner-CNN-bi-lstm-model-OBJECT-1.0035.hdf5\n",
      "Epoch 7/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.0362 - crf_viterbi_accuracy: 0.9989 - accuracy: 0.6841 - val_loss: 0.0399 - val_crf_viterbi_accuracy: 0.9954 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99513 to 0.99529, saving model to ner-CNN-bi-lstm-model-OBJECT-1.0035.hdf5\n",
      "Epoch 8/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.0249 - crf_viterbi_accuracy: 0.9990 - accuracy: 0.6841 - val_loss: 0.0298 - val_crf_viterbi_accuracy: 0.9953 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99529\n",
      "Epoch 9/10\n",
      "9822/9822 [==============================] - 11s 1ms/step - loss: 0.0142 - crf_viterbi_accuracy: 0.9992 - accuracy: 0.6841 - val_loss: 0.0200 - val_crf_viterbi_accuracy: 0.9953 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99529\n",
      "Epoch 10/10\n",
      "4448/9822 [============>.................] - ETA: 5s - loss: 0.0061 - crf_viterbi_accuracy: 0.9994 - accuracy: 0.6818"
     ]
    }
   ],
   "source": [
    "\n",
    "# Saving the best model only\n",
    "filepath=\"ner-CNN-bi-lstm-model-OBJECT-{val_accuracy:.2f}35.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the best model\n",
    "history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=10, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
    "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test, verbose=1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\",\"text\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "# test_pred = model.predict(X_test, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "\n",
    "i=5\n",
    "for w,true, pred in zip(X_test[i], test_labels[i] ,pred_labels[i]):\n",
    "    if words[w] != \"Urea\":\n",
    "        print(\"{:15}: {:5} {}\".format(words[w],true,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \" Tupp vaba, em.kael puhas, RR 155/85 mmhg .\"\n",
    "test_sentence = ''.join(test_sentence).split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=tag2idx[\"PAD\"], truncating='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(x_test_sent)\n",
    "p = pred2label(p)\n",
    "# p = np.argmax(p, axis=-1)\n",
    "print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "print(30 * \"=\")\n",
    "for w, pred in zip(test_sentence, p[0]):\n",
    "    print(\"{:15}: {:5}\".format(w, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
