{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = pd.read_csv(\"DataAnnotatedSubset150SentenceLength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ID</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46809</td>\n",
       "      <td>RR</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46809</td>\n",
       "      <td>130/80</td>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46809</td>\n",
       "      <td>mmHg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47482</td>\n",
       "      <td>RR142/89mmHg,</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47482</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_ID           word     tag\n",
       "0    46809             RR  object\n",
       "1    46809         130/80   value\n",
       "2    46809          mmHg.     NaN\n",
       "3    47482  RR142/89mmHg,  object\n",
       "4    47482             HR     NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS['tag'].fillna('unk', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27741"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(DS[\"word\"].values))\n",
    "n_words = len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(DS[\"tag\"].values))\n",
    "n_tags = len(tags); n_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"text_ID\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =[\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pt. tehtud 3 plasmaferees, talus hästi. Eemaldatud 700 ml plasmat. RR 112/60 mmHg. Tgasi 22.10.09.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unk', 'unk', 'unk', 'unk', 'unk', 'unk', 'unk', 'object', 'value', 'unk', 'unk', 'unk', 'unk', 'unk', 'unk']\n"
     ]
    }
   ],
   "source": [
    "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "print(labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = list(set(DS[\"tag\"].values))\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk': 0, 'object': 1, 'value': 2}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "bs = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "100%|██████████| 995526/995526 [00:01<00:00, 952753.12B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26', '.', '05', '.', '09', 'pats', '##ient', 'hospital', '##ise', '##eritud', 'er', '##üt', '##rots', '##ü', '##üt', '##ide', 'üle', '##kan', '##dek', '##s', ',', '2', 'do', '##osi', 'RR', '120', '/', '85', 'temperatuur', '37', '.', '7', '.', 'V', '##õe', '##tud', 'vere', '##ana', '##lü', '##üs', '##id', '.', 'En', '##ese', '##tun', '##ne', 'ra', '##huld', '##av', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (530 > 512). Running this sequence through BERT will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (533 > 512). Running this sequence through BERT will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (520 > 512). Running this sequence through BERT will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (560 > 512). Running this sequence through BERT will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"unk\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk': 0, 'object': 1, 'value': 2}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56445   119 63164 16107   124 49288 50544 10171   117 13675 10251   176\n",
      " 57747   119   142 18089 23388 16107 12367 58240 49288 10123   119 80993\n",
      " 16129   120 10709 10366 12396 10240   119   157 90612 10306   119 10150\n",
      "   119 11035   119     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the mask to ignore the padded elements in the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(attention_masks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we’re operating in pytorch, we have to convert the dataset to torch tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs).to(torch.int64)\n",
    "val_inputs = torch.tensor(val_inputs).to(torch.int64)\n",
    "tr_tags = torch.tensor(tr_tags).to(torch.int64)\n",
    "val_tags = torch.tensor(val_tags).to(torch.int64)\n",
    "tr_masks = torch.tensor(tr_masks).to(torch.int64)\n",
    "val_masks = torch.tensor(val_masks).to(torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10193984228923607\n",
      "Validation loss: 0.0823858518933141\n",
      "Validation Accuracy: 0.955373292727944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 1/5 [1:47:48<7:11:12, 6468.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.22283272283272285\n",
      "Train loss: 0.0648018626573806\n",
      "Validation loss: 0.07302507641183775\n",
      "Validation Accuracy: 0.964882336655592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 2/5 [3:32:16<5:20:24, 6408.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.2547386559448593\n",
      "Train loss: 0.05549227288186861\n",
      "Validation loss: 0.05696586536806683\n",
      "Validation Accuracy: 0.9615439276485791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 3/5 [5:16:13<3:31:53, 6356.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.29755835792862895\n",
      "Train loss: 0.04849204848869704\n",
      "Validation loss: 0.06190077107139798\n",
      "Validation Accuracy: 0.9587278516057584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 4/5 [7:00:17<1:45:23, 6323.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.2737290257951415\n",
      "Train loss: 0.04339630737619397\n",
      "Validation loss: 0.0593537884915984\n",
      "Validation Accuracy: 0.9576970284237725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [8:44:13<00:00, 6290.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.27697145621673924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0593537884915984\n",
      "Validation Accuracy: 0.9576970284237725\n",
      "Validation F1-Score: 0.4000379362670713\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for batch in valid_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                              attention_mask=b_input_mask, labels=b_labels)\n",
    "        logits = model(b_input_ids, token_type_ids=None,\n",
    "                       attention_mask=b_input_mask)\n",
    "        \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    true_labels.append(label_ids)\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    nb_eval_examples += b_input_ids.size(0)\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
    "valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
    "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
    "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "Ko             : object object\n",
      "##kku          : value value\n",
      "##v            : unk   unk\n",
      "##õ            : unk   unk\n",
      "##te           : unk   unk\n",
      ":              : unk   unk\n",
      "SK             : unk   unk\n",
      "##G            : unk   unk\n",
      "vale           : unk   unk\n",
      "##m            : unk   unk\n",
      ":              : unk   unk\n",
      "1              : unk   unk\n",
      "##D            : object unk\n",
      "A              : unk   unk\n",
      "(              : unk   object\n",
      "211            : unk   unk\n",
      ")              : unk   unk\n",
      "C              : unk   unk\n",
      "(              : unk   unk\n",
      "31             : unk   unk\n",
      ")              : unk   unk\n",
      "OM             : unk   unk\n",
      "(              : unk   unk\n",
      "2              : unk   unk\n",
      ")              : unk   unk\n",
      "D              : unk   unk\n",
      "(              : unk   unk\n",
      "201            : unk   unk\n",
      ")              : unk   unk\n",
      "PT             : unk   unk\n",
      "##CA           : unk   unk\n",
      "+              : unk   unk\n",
      "BM             : unk   unk\n",
      "##S            : unk   unk\n",
      "C              : unk   unk\n",
      "(              : unk   unk\n",
      "31             : unk   unk\n",
      ")              : unk   unk\n",
      "-              : unk   unk\n",
      "(              : unk   unk\n",
      "11             : unk   unk\n",
      ")              : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : object unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : value unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n",
      "[PAD]          : unk   unk\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(tokenizer.convert_ids_to_tokens(input_ids[i]), pred_tags[i], valid_tags[i]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(w, t, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pt',\n",
       " '.',\n",
       " 'teh',\n",
       " '##tud',\n",
       " '3',\n",
       " 'plasma',\n",
       " '##fere',\n",
       " '##es',\n",
       " ',',\n",
       " 'tal',\n",
       " '##us',\n",
       " 'h',\n",
       " '##ästi',\n",
       " '.',\n",
       " 'E',\n",
       " '##ema',\n",
       " '##lda',\n",
       " '##tud',\n",
       " '700',\n",
       " 'ml',\n",
       " 'plasma',\n",
       " '##t',\n",
       " '.',\n",
       " 'RR',\n",
       " '112',\n",
       " '/',\n",
       " '60',\n",
       " 'mm',\n",
       " '##H',\n",
       " '##g',\n",
       " '.',\n",
       " 'T',\n",
       " '##gasi',\n",
       " '22',\n",
       " '.',\n",
       " '10',\n",
       " '.',\n",
       " '09',\n",
       " '.',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 54\n",
    "max_len_char = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_word = [[word2idx[w[0]] for w in s] for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"PAD\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_char = []\n",
    "for sentence in sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word, y, test_size=0.1, random_state=2018)\n",
    "X_char_tr, X_char_te, _, _ = train_test_split(X_char, y, test_size=0.1, random_state=2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "# input and embedding for words\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=20,\n",
    "                     input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
    "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                               recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_lstm)\n",
    "\n",
    "model = Model([word_in, char_in], out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 54, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 54)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 54, 10, 10)   1060        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 54, 20)       554860      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 54, 20)       2480        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 54, 40)       0           embedding_1[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 54, 40)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 54, 100)      36400       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 54, 4)        404         bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 595,204\n",
      "Trainable params: 595,204\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11050 samples, validate on 1228 samples\n",
      "Epoch 1/10\n",
      "11050/11050 [==============================] - 56s 5ms/step - loss: 0.0627 - acc: 0.9314 - val_loss: 0.0127 - val_acc: 0.9850\n",
      "Epoch 2/10\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 0.0096 - acc: 0.9889 - val_loss: 0.0060 - val_acc: 0.9919\n",
      "Epoch 3/10\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 0.0048 - acc: 0.9942 - val_loss: 0.0049 - val_acc: 0.9939\n",
      "Epoch 4/10\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 0.0024 - acc: 0.9968 - val_loss: 0.0046 - val_acc: 0.9939\n",
      "Epoch 5/10\n",
      "11050/11050 [==============================] - 50s 5ms/step - loss: 0.0014 - acc: 0.9981 - val_loss: 0.0046 - val_acc: 0.9939\n",
      "Epoch 6/10\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 0.0011 - acc: 0.9986 - val_loss: 0.0048 - val_acc: 0.9933\n",
      "Epoch 7/10\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 8.4861e-04 - acc: 0.9989 - val_loss: 0.0046 - val_acc: 0.9938\n",
      "Epoch 8/10\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 7.4867e-04 - acc: 0.9990 - val_loss: 0.0051 - val_acc: 0.9926\n",
      "Epoch 9/10\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 7.1445e-04 - acc: 0.9991 - val_loss: 0.0048 - val_acc: 0.9940\n",
      "Epoch 10/10\n",
      "11050/11050 [==============================] - 53s 5ms/step - loss: 5.9169e-04 - acc: 0.9992 - val_loss: 0.0049 - val_acc: 0.9942\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"acc\"])\n",
    "plt.plot(hist[\"val_acc\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_word_te,\n",
    "                        np.array(X_char_te).reshape((len(X_char_te),\n",
    "                                                     max_len, max_len_char))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "Kardiovaskulaarsüsteem:: unk   unk\n",
      "RR             : object object\n",
      "160/100mmHg.   : value value\n",
      "Ausk-l         : unk   unk\n",
      "s-toonid       : unk   unk\n",
      "reg,           : unk   unk\n",
      "puhtad,        : unk   unk\n",
      "fr.            : unk   unk\n",
      "60*min.        : unk   unk\n",
      "Kardiovaskulaarsüsteem:: unk   unk\n",
      "RR             : object object\n",
      "160/100mmHg.   : value value\n",
      "Ausk-l         : unk   unk\n",
      "s-toonid       : unk   unk\n",
      "reg,           : unk   unk\n",
      "puhtad,        : unk   unk\n",
      "fr.            : unk   unk\n",
      "60*min.        : unk   unk\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "p = np.argmax(y_pred[i], axis=-1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_word_te[i], y_te[i], p):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p, axis=-1)\n",
    "            out_i.append(idx2tag[p_i])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "pred_labels = pred2label(y_pred)\n",
    "\n",
    "def pred2labelV2(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            out_i.append(idx2tag[p])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "test_labels = pred2labelV2(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unk', 'unk', 'unk', 'unk', 'unk', 'object', 'value', 'unk', 'unk', 'unk', 'unk', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk\n",
      "[3 3 3 3 3 2 1 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(idx2tag[3])\n",
    "print(y_te[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 54.6%\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PAD       0.00      0.00      0.00     58220\n",
      "      object       0.33      0.97      0.50      1050\n",
      "         unk       0.21      1.00      0.34     13658\n",
      "       value       0.18      0.97      0.30       782\n",
      "\n",
      "    accuracy                           0.21     73710\n",
      "   macro avg       0.18      0.73      0.28     73710\n",
      "weighted avg       0.04      0.21      0.07     73710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11050 samples, validate on 1228 samples\n",
      "Epoch 1/20\n",
      "11050/11050 [==============================] - 50s 4ms/step - loss: 5.5176e-04 - acc: 0.9992 - val_loss: 0.0052 - val_acc: 0.9920\n",
      "Epoch 2/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 5.0278e-04 - acc: 0.9994 - val_loss: 0.0051 - val_acc: 0.9933\n",
      "Epoch 3/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 4.4895e-04 - acc: 0.9995 - val_loss: 0.0048 - val_acc: 0.9945\n",
      "Epoch 4/20\n",
      "11050/11050 [==============================] - 48s 4ms/step - loss: 4.5015e-04 - acc: 0.9994 - val_loss: 0.0051 - val_acc: 0.9931\n",
      "Epoch 5/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 4.4827e-04 - acc: 0.9993 - val_loss: 0.0050 - val_acc: 0.9944\n",
      "Epoch 6/20\n",
      "11050/11050 [==============================] - 48s 4ms/step - loss: 3.7821e-04 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9922\n",
      "Epoch 7/20\n",
      "11050/11050 [==============================] - 48s 4ms/step - loss: 3.5568e-04 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9931\n",
      "Epoch 8/20\n",
      "11050/11050 [==============================] - 48s 4ms/step - loss: 3.2257e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9930\n",
      "Epoch 9/20\n",
      "11050/11050 [==============================] - 50s 5ms/step - loss: 3.4625e-04 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9925\n",
      "Epoch 10/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 2.8369e-04 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9933\n",
      "Epoch 11/20\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 2.7029e-04 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9919\n",
      "Epoch 12/20\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 2.8819e-04 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9939\n",
      "Epoch 13/20\n",
      "11050/11050 [==============================] - 50s 5ms/step - loss: 2.6187e-04 - acc: 0.9996 - val_loss: 0.0061 - val_acc: 0.9926\n",
      "Epoch 14/20\n",
      "11050/11050 [==============================] - 51s 5ms/step - loss: 2.5836e-04 - acc: 0.9996 - val_loss: 0.0059 - val_acc: 0.9925\n",
      "Epoch 15/20\n",
      "11050/11050 [==============================] - 52s 5ms/step - loss: 2.7288e-04 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9943\n",
      "Epoch 16/20\n",
      "11050/11050 [==============================] - 52s 5ms/step - loss: 2.4597e-04 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9928\n",
      "Epoch 17/20\n",
      "11050/11050 [==============================] - 50s 4ms/step - loss: 2.1781e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9933\n",
      "Epoch 18/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 2.4442e-04 - acc: 0.9997 - val_loss: 0.0062 - val_acc: 0.9932\n",
      "Epoch 19/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 2.1906e-04 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9928\n",
      "Epoch 20/20\n",
      "11050/11050 [==============================] - 49s 4ms/step - loss: 2.0300e-04 - acc: 0.9997 - val_loss: 0.0062 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=32, epochs=20, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.991951</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.999216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.993268</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.999360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.994512</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.999480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.993122</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.999408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.994366</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.999344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.992244</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.999544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.993122</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.999456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.993048</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.999496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.992463</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.999552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.993341</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.999656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.991878</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.999632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.999616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.999616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.992536</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.999608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.994292</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.999552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.992756</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.999688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.993268</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.999680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.993195</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.999680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.992829</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.992975</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.999728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss   val_acc      loss       acc\n",
       "0   0.005189  0.991951  0.000552  0.999216\n",
       "1   0.005057  0.993268  0.000503  0.999360\n",
       "2   0.004751  0.994512  0.000449  0.999480\n",
       "3   0.005068  0.993122  0.000450  0.999408\n",
       "4   0.005039  0.994366  0.000448  0.999344\n",
       "5   0.005415  0.992244  0.000378  0.999544\n",
       "6   0.005571  0.993122  0.000356  0.999456\n",
       "7   0.005711  0.993048  0.000323  0.999496\n",
       "8   0.005446  0.992463  0.000346  0.999552\n",
       "9   0.005533  0.993341  0.000284  0.999656\n",
       "10  0.005793  0.991878  0.000270  0.999632\n",
       "11  0.005456  0.993853  0.000288  0.999616\n",
       "12  0.006058  0.992609  0.000262  0.999616\n",
       "13  0.005919  0.992536  0.000258  0.999608\n",
       "14  0.005564  0.994292  0.000273  0.999552\n",
       "15  0.005882  0.992756  0.000246  0.999688\n",
       "16  0.005951  0.993268  0.000218  0.999680\n",
       "17  0.006177  0.993195  0.000244  0.999680\n",
       "18  0.006125  0.992829  0.000219  0.999672\n",
       "19  0.006234  0.992975  0.000203  0.999728"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model.predict([X_word_te,\n",
    "                        np.array(X_char_te).reshape((len(X_char_te),\n",
    "                                                     max_len, max_len_char))])\n",
    "p2 = np.argmax(y_pred2[i], axis=-1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kardiovaskulaarsüsteem:: unk   unk\n",
      "RR             : object object\n",
      "105/70         : value value\n",
      "mmHg           : unk   unk\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "for w, t, pred in zip(X_word_te[i], y_te[i], p2):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 54.6%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_labels2 = pred2label(y_pred2)\n",
    "test_labels2 = pred2labelV2(y_te)\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels2, pred_labels2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PAD       0.00      0.00      0.00     58220\n",
      "      object       0.48      0.97      0.64      1050\n",
      "         unk       0.21      1.00      0.34     13658\n",
      "       value       0.15      0.98      0.26       782\n",
      "\n",
      "    accuracy                           0.21     73710\n",
      "   macro avg       0.21      0.74      0.31     73710\n",
      "weighted avg       0.05      0.21      0.07     73710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report2 = flat_classification_report(y_pred=pred_labels2, y_true=test_labels2)\n",
    "print(report2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2/3 * (max_len * max_len_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 54, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 54)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 54, 10, 10)   1060        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 54, 50)       1387150     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 54, 50)       12200       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 54, 100)      0           embedding_5[0][0]                \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 54, 100)      0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 54, 720)      1327680     spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 54, 4)        2884        bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 2,730,974\n",
      "Trainable params: 2,730,974\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "# input and embedding for words\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=50,\n",
    "                     input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
    "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=50, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.4)(x)\n",
    "main_lstm = Bidirectional(LSTM(units=360, return_sequences=True,\n",
    "                               recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_lstm)\n",
    "\n",
    "model2 = Model([word_in, char_in], out)\n",
    "\n",
    "\n",
    "model2.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11050 samples, validate on 1228 samples\n",
      "Epoch 1/20\n",
      "11050/11050 [==============================] - 202s 18ms/step - loss: 0.0383 - acc: 0.9575 - val_loss: 0.0064 - val_acc: 0.9911\n",
      "Epoch 2/20\n",
      "11050/11050 [==============================] - 212s 19ms/step - loss: 0.0050 - acc: 0.9937 - val_loss: 0.0038 - val_acc: 0.9943\n",
      "Epoch 3/20\n",
      "11050/11050 [==============================] - 214s 19ms/step - loss: 0.0024 - acc: 0.9968 - val_loss: 0.0037 - val_acc: 0.9947\n",
      "Epoch 4/20\n",
      "11050/11050 [==============================] - 210s 19ms/step - loss: 0.0014 - acc: 0.9983 - val_loss: 0.0037 - val_acc: 0.9955\n",
      "Epoch 5/20\n",
      "11050/11050 [==============================] - 213s 19ms/step - loss: 9.0499e-04 - acc: 0.9987 - val_loss: 0.0044 - val_acc: 0.9935\n",
      "Epoch 6/20\n",
      "11050/11050 [==============================] - 214s 19ms/step - loss: 7.3151e-04 - acc: 0.9991 - val_loss: 0.0039 - val_acc: 0.9952\n",
      "Epoch 7/20\n",
      "11050/11050 [==============================] - 211s 19ms/step - loss: 6.5961e-04 - acc: 0.9992 - val_loss: 0.0047 - val_acc: 0.9934\n",
      "Epoch 8/20\n",
      "11050/11050 [==============================] - 205s 19ms/step - loss: 5.7713e-04 - acc: 0.9992 - val_loss: 0.0051 - val_acc: 0.9923\n",
      "Epoch 9/20\n",
      "11050/11050 [==============================] - 204s 18ms/step - loss: 5.0009e-04 - acc: 0.9993 - val_loss: 0.0044 - val_acc: 0.9948\n",
      "Epoch 10/20\n",
      "11050/11050 [==============================] - 206s 19ms/step - loss: 5.3117e-04 - acc: 0.9992 - val_loss: 0.0053 - val_acc: 0.9928\n",
      "Epoch 11/20\n",
      " 4960/11050 [============>.................] - ETA: 1:49 - loss: 5.0780e-04 - acc: 0.9993"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=32, epochs=20, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model2.predict([X_word_te,\n",
    "                        np.array(X_char_te).reshape((len(X_char_te),\n",
    "                                                     max_len, max_len_char))])\n",
    "p3 = np.argmax(y_pred3[i], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "04.12.2012     : unk   unk\n",
      "-              : unk   unk\n",
      "RR             : object unk\n",
      "180/80         : value unk\n",
      "mmHg,          : unk   unk\n",
      "fr.            : unk   object\n",
      "87             : unk   value\n",
      "x`,            : unk   unk\n",
      "O2             : unk   unk\n",
      "saturatsioon   : unk   unk\n",
      "98%,           : unk   unk\n",
      "kaal           : unk   unk\n",
      "60             : unk   unk\n",
      "kg.            : unk   unk\n",
      "pikkus         : unk   unk\n",
      "1.50           : unk   unk\n",
      "cm.            : unk   unk\n",
      ".              : unk   unk\n"
     ]
    }
   ],
   "source": [
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "i=103\n",
    "for w, t, pred in zip(X_word_te[i], y_te[i], p3):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 54.4%\n"
     ]
    }
   ],
   "source": [
    "pred_labels3 = pred2label(y_pred3)\n",
    "test_labels3 = pred2labelV2(y_te)\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels3, pred_labels3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PAD       0.00      0.00      0.00     58220\n",
      "      object       0.29      0.98      0.45      1050\n",
      "         unk       0.21      1.00      0.34     13658\n",
      "       value       0.20      0.97      0.33       782\n",
      "\n",
      "    accuracy                           0.21     73710\n",
      "   macro avg       0.17      0.74      0.28     73710\n",
      "weighted avg       0.04      0.21      0.07     73710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report3 = flat_classification_report(y_pred=pred_labels3, y_true=test_labels3)\n",
    "print(report3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \" Tupp vaba, em.kael puhas, RR 155/85 mmhg , emakas vÃ¤ike, adn.ii.\"\n",
    "test_sentence = ''.join(test_sentence).split() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(x_test_sent,X_char_mytest)\n",
    "\n",
    "# p = model.predict(x_test_sent)\n",
    "# p = np.argmax(p, axis=-1)\n",
    "\n",
    "# print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "# print(30 * \"=\")\n",
    "# for w, pred in zip(test_sentence, p[0]):\n",
    "#     print(\"{:15}: {:5}\".format(w, tags[pred]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
