{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('X_train.txt', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open('X_test.txt', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open('y_train.txt', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('y_test.txt', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras_contrib.layers.crf import CRF, crf_loss, crf_viterbi_accuracy\n",
    "model = load_model('ner-CNN-bi-lstm-model-FULL-0.99.hdf5', custom_objects={'CRF':CRF, 'crf_loss': crf_loss,'crf_viterbi_accuracy': crf_viterbi_accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import future\n",
    "\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from math import nan\n",
    "\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM,MaxPooling1D,Flatten,Embedding, Dense, TimeDistributed, Conv1D,Dropout, Bidirectional\n",
    "import keras as k\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "DS = pd.read_csv(\"DataAnnotatedExampleFullV2.csv\")\n",
    "DS['tag'].fillna('unk', inplace=True)\n",
    "data = DS[['text_ID','word','tag']]\n",
    "data.columns = ['sentence_idx','word','tag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17026984"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tags = [\"unk\",\"value\",\"object\"]\n",
    "tags = []\n",
    "for tag in set(data[\"tag\"].values):\n",
    "    if tag is nan or isinstance(tag, float):\n",
    "        tags.append('unk')\n",
    "    else:\n",
    "        tags.append(tag)\n",
    "n_tags = len(tags)\n",
    "\n",
    "from future.utils import iteritems\n",
    "\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 0, 'unk': 1, 'value': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'object', 1: 'unk', 2: 'value'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unk       16482502\n",
       "value       430906\n",
       "object      113576\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS[\"tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6162/6162 [==============================] - 153s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "test_pred = model.predict(X_test, verbose=1) \n",
    "import numpy as np\n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 3.6%\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasutaja\\Anaconda3\\envs\\myEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      object       0.00      0.00      0.00      8243\n",
      "         unk       0.00      0.00      0.00      9748\n",
      "       value       0.98      0.99      0.99   1072683\n",
      "\n",
      "    accuracy                           0.98   1090674\n",
      "   macro avg       0.33      0.33      0.33   1090674\n",
      "weighted avg       0.97      0.98      0.97   1090674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels,labels=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = {}\n",
    "TN = {}\n",
    "FP = {}\n",
    "FN = {}\n",
    "for tag in tag2idx.keys():\n",
    "    TP[tag] = 0\n",
    "    TN[tag] = 0    \n",
    "    FP[tag] = 0    \n",
    "    FN[tag] = 0    \n",
    "\n",
    "def accumulate_score_by_tag(gt, pred):\n",
    "    \"\"\"\n",
    "    For each tag keep stats\n",
    "    \"\"\"\n",
    "    if gt == pred:\n",
    "        TP[gt] += 1\n",
    "    elif gt != 'O' and pred == 'O':\n",
    "        FN[gt] +=1\n",
    "    elif gt == 'O' and pred != 'O':\n",
    "        FP[gt] += 1\n",
    "    else:\n",
    "        TN[gt] += 1\n",
    "for i, sentence in enumerate(X_test):\n",
    "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
    "    gt = np.argmax(y_test[0], axis=-1)\n",
    "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
    "        accumulate_score_by_tag(idx2tag[gt[idx]],tags[pred])\n",
    "for tag in tag2idx.keys():\n",
    "    print(f'tag:{tag}')    \n",
    "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
    "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))\n",
    "#Reference: https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainLabel = pred2label(y_train)\n",
    "train_labelsargmaxList = list(itertools.chain.from_iterable(y_trainLabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labelsargmaxList.count(\"value\"))\n",
    "print(train_labelsargmaxList.count(\"object\"))\n",
    "print(train_labelsargmaxList.count(\"unk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "T\n",
    "test_labelsargmaxList = list(itertools.chain.from_iterable(test_labels))\n",
    "print(test_labelsargmaxList.count(\"value\"))\n",
    "print(test_labelsargmaxList.count(\"object\"))\n",
    "print(test_labelsargmaxList.count(\"unk\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labelsargmaxList = list(itertools.chain.from_iterable(pred_labels))\n",
    "print(pred_labelsargmaxList.count(\"value\"))\n",
    "print(pred_labelsargmaxList.count(\"object\"))\n",
    "print(pred_labelsargmaxList.count(\"unk\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
